{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Self-attention & architecture Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import click\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import logging\n",
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 500\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# outils avancés de gestion des chemins\n",
    "BASEPATH = Path(\"/tmp/runs/\")\n",
    "TB_PATH =  BASEPATH / \"logs\"\n",
    "TB_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# usage externe de tensorboard: (1) lancer la commande dans une console; (2) copier-coller l'URL dans un navigateur\n",
    "display(HTML(\"<h2>Informations</h2><div>Pour visualiser les logs, tapez la commande : </div>\"))\n",
    "print(f\"tensorboard --logdir {Path(TB_PATH).absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe de gestion des données textuelles (idem TP précédent)\n",
    "\n",
    "1. Récupération d'embedding glove\n",
    "    1. Téléchargement:\n",
    "    ```wget http://nlp.stanford.edu/data/glove.6B.zip```\n",
    "    2. Lecture des fichiers\n",
    "2. Récupération des données imdb (classification d'opinion)\n",
    "3. Traitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_glove(PATH, EMB_SIZE=50):\n",
    "    vocab,embeddings = [],[]\n",
    "    with open(PATH+'glove.6B.{:d}d.txt'.format(EMB_SIZE),'rt') as fi:\n",
    "        full_content = fi.read().strip().split('\\n')\n",
    "    for i in range(len(full_content)):\n",
    "        i_word = full_content[i].split(' ')[0]\n",
    "        i_embeddings = [float(val) for val in full_content[i].split(' ')[1:]]\n",
    "        vocab.append(i_word)\n",
    "        embeddings.append(i_embeddings)\n",
    "    return vocab, embeddings\n",
    "\n",
    "# recuperation des embbeding \n",
    "EMB_SIZE = 50 # 100, 200 or 300\n",
    "PATH = \"./data/glove/glove.6B/\" # répertoire où vous avez récupéré les embeddings\n",
    "vocab, embeddings = get_embeddings_glove(PATH, EMB_SIZE=EMB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5\n",
    "for i in range(n):\n",
    "    print(vocab[i]) # premier mot\n",
    "    print(len(embeddings[i]), embeddings[i]) # premier embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération via huggingface des données imdb\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('imdb')\n",
    "\n",
    "# dataset[\"train\"][0]\n",
    "print(dataset[\"train\"][0]['text'])\n",
    "print(dataset[\"train\"][0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FolderText(Dataset):\n",
    "    \"\"\"Dataset gérant la tokenization des documents à la volée\"\"\"\n",
    "\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.txts   = [data[i][\"text\"] for i in range(len(data))]\n",
    "        self.labels = [data[i][\"label\"] for i in range(len(data))]\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        return self.tokenizer(self.txts[ix]), self.labels[ix]\n",
    "    def get_txt(self,ix):\n",
    "        # s = self.txts[ix]\n",
    "        return self.txts[ix], self.labels[ix]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(vocab, embeddings):\n",
    "    # mise en forme du dataset\n",
    "    WORDS = re.compile(r\"\\S+\")\n",
    "\n",
    "    embedding_size = len(embeddings[0])\n",
    "    OOVID = len(vocab)\n",
    "    vocab.append(\"__OOV__\")\n",
    "    word2id = {word: ix for ix, word in enumerate(vocab)}\n",
    "    embeddings = np.vstack((embeddings, np.zeros(embedding_size)))\n",
    "\n",
    "    def tokenizer(t):\n",
    "        return [word2id.get(x, OOVID) for x in re.findall(WORDS, t.lower())]\n",
    "\n",
    "    logging.info(\"Loading embeddings\")\n",
    "    logging.info(\"Get the IMDB dataset\")\n",
    "\n",
    "    train_data, test_data=FolderText(dataset[\"train\"], tokenizer), FolderText(dataset[\"test\"], tokenizer)\n",
    "    id2word = dict((v, k) for k, v in word2id.items())\n",
    "    return train_data, test_data, embeddings, tokenizer, id2word\n",
    "\n",
    "\n",
    "train_data, test_data, embeddings, tokenizer, id2word = format_dataset(vocab, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérification rapide du bon fonctionnemnet des éléments ci-dessus\n",
    "\n",
    "sent = \"The movie was great\"\n",
    "ind = tokenizer(sent)\n",
    "print(ind)\n",
    "print(\"check reconstruction :\", \" \".join([id2word[i] for i in ind]))\n",
    "\n",
    "# avec un mot inconnu\n",
    "sent = \"this movie was qslkjgf\"\n",
    "ind = tokenizer(sent)\n",
    "print(ind)\n",
    "print(\"check reconstruction :\", \" \".join([id2word[i] for i in ind]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation de l'attention propre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax(x,lens=None):\n",
    "    #X : B x N x N\n",
    "    if lens is None:\n",
    "        lens = torch.zeros(x.size(0),1).fill_(x.size(1)).to(x.device)\n",
    "    \n",
    "    return x.softmax(-1).nan_to_num(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la fonction ci dessus calcul e softmax pour vous = normalise l'attention ... Avec un masque d'attention!\n",
    "\n",
    "# TODO :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBasicLayer(nn.Module):\n",
    "    def __init__(self,dim,layer_norm=True):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(dim,dim)\n",
    "        self.value = nn.Linear(dim,dim)\n",
    "        self.query = nn.Linear(dim,dim)\n",
    "        self.final =  nn.Linear(dim,dim)\n",
    "\n",
    "    def forward(self,x,lens=None): ## B x L x Z\n",
    "        # 0. Regarder la documentation de bmm !!\n",
    "        # 1. Q, K, V\n",
    "        # 2.  d_k   = query.size(-1)\n",
    "        # 3. score\n",
    "        # 4. a = masked_softmax(scores,lens)\n",
    "        #  TODO \n",
    "\n",
    "        out = F.relu(self.final(out))\n",
    "        return out \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compréhension:\n",
    "1. Afficher les dimensions des différentes matrices\n",
    "2. Afficher la matrice d'attention propre\n",
    "3. Comparer les objets à leur entrée puis sortie du système"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si on met des données random\n",
    "B = 2   # batch\n",
    "L = 10  # length\n",
    "Z = 50  # dim_embedding\n",
    "x = torch.rand(B,L,Z)\n",
    "net = AttentionBasicLayer(Z,layer_norm=True)\n",
    "out,scores = net(x)\n",
    "\n",
    "print(out.size(), scores.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-attention\n",
    "# - symétrique?\n",
    "# - diagonale forte?\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(scores[0].to(\"cpu\").detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quelle est la différence entre l'entrée et la sortie\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(x[0,:,:].to(\"cpu\").numpy()) # instance 1\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(out[0,:,:].to(\"cpu\").detach().numpy()) # instance 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reste du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionResidualLayer(nn.Module):\n",
    "    def __init__(self,dim):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(dim,dim)\n",
    "        self.value = nn.Linear(dim,dim)\n",
    "        self.query = nn.Linear(dim,dim)\n",
    "        self.final =  nn.Linear(dim,dim)\n",
    "        self.layer_norm = nn.LayerNorm(dim)\n",
    "    def forward(self,x,lens=None): ## B x L x D\n",
    "        x = self.layer_norm(x)\n",
    "        # A compléter\n",
    "        #  TODO \n",
    "        # regarder la différence avec la fonction précédente !!\n",
    "        out = F.relu(self.final(x+out)) # care of the details\n",
    "        return out\n",
    "\n",
    "class SelfAttentionModel(nn.Module):\n",
    "    def __init__(self, dim, attention, nclasses=2,numlayers=3,pos_emb=False):\n",
    "        super().__init__()\n",
    "        self.pos_emb =  nn.Embedding(MAX_LENGTH,dim) if pos_emb else None\n",
    "        self.final = nn.Linear(dim,nclasses)\n",
    "        self.attention = nn.ModuleList([attention(dim) for _ in range(numlayers)])\n",
    "    \n",
    "    def forward(self,x,lens=None):\n",
    "        # tout est donné... Mais il faut le comprendre\n",
    "        out = x\n",
    "        if self.pos_emb is not None:\n",
    "            pos = torch.arange(x.size(1)).to(x.device)\n",
    "            pos = self.pos_emb(pos).unsqueeze(0).expand(x.size(0),x.size(1),x.size(2))\n",
    "            out = x + pos\n",
    "        for att in self.attention:\n",
    "            out = att(out,lens)\n",
    "        return self.final(out.sum(1)/lens.view(-1,1)) # pooling\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    \"\"\"Base class for supervised learning\"\"\"\n",
    "\n",
    "    def __init__(self, model, model_id: str):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.optim = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "        self.model_id = model_id\n",
    "        self.iteration = 0\n",
    "\n",
    "    def run(self,train_loader, test_loader, epochs, test_iterations):\n",
    "        \"\"\"Run a model during `epochs` epochs\"\"\"\n",
    "        writer = SummaryWriter(f\"/tmp/runs/{self.model_id}\")\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        loss_nagg = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "        self.model.train()\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            # Iterate over batches\n",
    "            for x, y,lens in train_loader:\n",
    "                self.optim.zero_grad()\n",
    "                yhat = self.model(x,lens)\n",
    "                l = loss(yhat, y)\n",
    "                l.backward()\n",
    "                self.optim.step()\n",
    "                writer.add_scalar('loss/train', l, self.iteration)\n",
    "                self.iteration += 1\n",
    "                \n",
    "                if self.iteration % test_iterations == 0:\n",
    "                    self.model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        cumloss = 0\n",
    "                        cumcorrect = 0\n",
    "                        count = 0\n",
    "                        for x, y, lens in test_loader:\n",
    "                            yhat = self.model(x,lens)\n",
    "                            cumloss += loss_nagg(yhat, y)\n",
    "                            cumcorrect += (yhat.argmax(1) == y).sum()\n",
    "                            count += x.shape[0]\n",
    "                            \n",
    "                        writer.add_scalar(\n",
    "                            'loss/test', cumloss.item() / count, self.iteration)\n",
    "                        writer.add_scalar(\n",
    "                            'correct/test', cumcorrect.item() / count, self.iteration)\n",
    "                        \n",
    "                        \n",
    "                    self.model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collate(batch):\n",
    "#     \"\"\" Collate function for DataLoader \"\"\"\n",
    "#     data = [torch.LongTensor(item[0][:MAX_LENGTH]) for item in batch]\n",
    "#     lens = [len(d) for d in data]\n",
    "#     labels = [item[1] for item in batch]\n",
    "#     return emb_layer(torch.nn.utils.rnn.pad_sequence(data, batch_first=True,padding_value = PAD)).to(device)\\\n",
    "#         , torch.LongTensor(labels).to(device), torch.Tensor(lens).to(device)\n",
    "\n",
    "# sorties des cahrgements de données/embedding précédents\n",
    "PAD = word2id[\"__OOV__\"] # variable globale pour collate\n",
    "embeddings = torch.Tensor(embeddings)\n",
    "emb_layer = nn.Embedding.from_pretrained(torch.Tensor(embeddings))   \n",
    "MAX_LENGTH = 500 # tout ce qui se trouve après est éliminé\n",
    "\n",
    "def collate(batch):\n",
    "        \"\"\" Collate function for DataLoader \"\"\"\n",
    "        data = [torch.LongTensor(item[0][:MAX_LENGTH]) for item in batch]\n",
    "        lens = [len(d) for d in data]\n",
    "        labels = [item[1] for item in batch]\n",
    "        return emb_layer(torch.nn.utils.rnn.pad_sequence(data, batch_first=True,padding_value = PAD)).to(device), torch.LongTensor(labels).to(device), torch.Tensor(lens).to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "emb_size = 50\n",
    "modeltype = 2\n",
    "epochs = 50\n",
    "test_iterations = 1000\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True,\n",
    "                        batch_size=batch_size, collate_fn=collate)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size,collate_fn=collate,shuffle=False)\n",
    "## [[STUDENT]]\n",
    "if modeltype == 0:\n",
    "    model = SelfAttentionModel(emb_size,AttentionBasicLayer,2,1).to(device)\n",
    "elif modeltype == 1:\n",
    "    model = SelfAttentionModel(emb_size,AttentionResidualLayer,2,3).to(device)\n",
    "elif modeltype == 2:\n",
    "    model = SelfAttentionModel(emb_size,AttentionResidualLayer,2,3,True).to(device)\n",
    "else:\n",
    "    print(\"No model of this type\")\n",
    "    exit(1)\n",
    "learner = Learner(model, time.asctime())\n",
    "learner.run(train_loader,test_loader,epochs,test_iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_model(model,fichier): # pas de sauvegarde de l'optimiseur ici\n",
    "      \"\"\" sauvegarde du modèle dans fichier \"\"\"\n",
    "      state = {'model_state': model.state_dict()}\n",
    "      torch.save(state,fichier) # pas besoin de passer par pickle\n",
    " \n",
    "def load_model(fichier,model):\n",
    "      \"\"\" Si le fichier existe, on charge le modèle  \"\"\"\n",
    "      if os.path.isfile(fichier):\n",
    "          state = torch.load(fichier)\n",
    "          model.load_state_dict(state['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarde du réseau (économie de 30 minutes :)\n",
    "# ATTENTION: pour que ça marche, il faut que les réseaux soient structurellement identiques... Il vous faut donc ma correction :)\n",
    "# la classe utilisée est dans model.py dans le répertoire model.\n",
    "\n",
    "path = \"./model/\"\n",
    "\n",
    "model.name =\"transfo-res-posemb-l3\" # transformation du nom pour normaliser\n",
    "fichier = path+f\"{model.name}\"\n",
    "save_model(model,fichier)\n",
    "\n",
    "\n",
    "# vous pouvez utiliser les formules symmétriques pour le chargement\n",
    "\n",
    "# transfo1 = SelfAttentionModel(emb_size,AttentionBasicLayer,2,1).to(device).to(device)\n",
    "# transfo1.name =\"transfo-base-l1\"\n",
    "\n",
    "# load_model(path+\"/trasnfo-base-l1\", transfo1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalaution des performances en test\n",
    "#  TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthode optimisée pour générer des embeddings de position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Position embeddings\"\n",
    "\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        \"\"\"Génère des embeddings de position\n",
    "\n",
    "        Args:\n",
    "            d_model (int): Dimension des embeddings à générer\n",
    "            max_len (int, optional): Longueur maximale des textes. \n",
    "                Attention, plus cette valeur est haute, moins bons seront les embeddings de position.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model, dtype=torch.float)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        pe.requires_grad = False\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Ajoute les embeddings de position\"\"\"\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PositionalEncoding(EMB_SIZE, max_len=MAX_LENGTH)\n",
    "print(pe.pe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "length = 200\n",
    "with torch.no_grad():\n",
    "    # Draw a heatmap with the numeric values in each cell\n",
    "    pes = pe(torch.zeros(1, length, emb_size)).squeeze() # batch x length x emb\n",
    "\n",
    "    inners = pes @ pes.t()\n",
    "    f, ax = plt.subplots(figsize=(9, 6))\n",
    "    sns.heatmap(inners, annot=False, fmt=\"d\", ax=ax, cmap=\"coolwarm\")\n",
    "    f.show()\n",
    "    input(\"Press Enter to continue...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  TODO )\",\" TODO \",\\\n",
    "    txt, flags=re.DOTALL))\n",
    "f2.close()\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
