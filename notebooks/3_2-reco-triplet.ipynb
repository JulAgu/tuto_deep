{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf943d4c-ac09-42ad-b098-db274b1d414e"
      },
      "source": [
        "#  Apprentissage de représentation et triplet loss\n",
        "\n",
        "Vincent Guigue\n",
        "\n",
        "Enoncé dérivé de celui de Nicolas Baskiotis (nicolas.baskiotis@sorbonne-universite.fr) -- MLIA/ISIR, Sorbonne Université"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkA5bY4bdmM9"
      },
      "source": [
        "Importation des modules nécessaires et configuration de torch/tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlMylH6fdZXO"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from random import shuffle\n",
        "from torch import optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorboard import notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtdCHwUTjLHy"
      },
      "outputs": [],
      "source": [
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs\n",
        "\n",
        "writer = SummaryWriter()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a71eb410-57c8-4ba5-ad45-fb80563e97c6"
      },
      "source": [
        "# Jeu de données de recommandation\n",
        "Ce jeu de données est issu d'un célèbre site sur les jeux de société. Il contient les fichiers suivants :\n",
        "\n",
        "\n",
        "*   `users.csv `: liste des utilisateurs et de leur identifiant sous la forme `(nickname, id)`\n",
        "*   `jeux.csv` : liste des jeux et de leur identifiant sous la forme `(id, titre, titre complet, résumé, catégories, âge)`\n",
        "* `avis.csv` : liste des avis sous la forme `(id,id_jeu,id_user,titre, nickname, date, note, titre commentaire, commentaire)`\n",
        "\n",
        "Dans cette première partie, nous allons nous intéresser uniquement aux notes données aux jeux par les utilisateurs, sans regarder le contenu. L'objectif est de prédire la note qu'un utilisateur donne à un jeu. Ce problème peut être vu comme de la régression sur la note ou comme un problème de classification multi-classes en discrétisant la note.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJsBVeI3i_FO"
      },
      "source": [
        "On installe tout d'abord les données sur le colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgmBm4G5gxQ5"
      },
      "outputs": [],
      "source": [
        "# pour Colab (cf ci-dessous pour travailler en local)\n",
        "\n",
        "# ## Télécharger le fichier donnees_jds.zip dans votre google drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/',force_remount=True)\n",
        "# ## Changer le PATH vers le fichier de données\n",
        "# PATH = \"/content/drive/MyDrive/data/data_jds/\"\n",
        "# # On décompresse le fichier, les fichiers seront au niveau de /content\n",
        "# !unzip $PATH\"donnees_jds.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# local\n",
        "PATH = \"data/donnees_jds/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33WTifJXeVcN"
      },
      "source": [
        "Nous allons dans un premier temps filtrer les données pour ne garder que des utilisateurs et des jeux ayant suffisament de notes.\n",
        "\n",
        "**Note:** on se rend vite compte que ce filtrage n'est pas si évident (le nb de revues par objet dépend des auteurs et vice et versa). On procède de manière itérative, jusqu'à convergence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXjUftoQeSwI"
      },
      "outputs": [],
      "source": [
        "\n",
        "def filtre(data,ths_g,ths_u):\n",
        "    \"\"\" filtre les données pour ne garder que des jeux ayant plus de ths_g notes et des users avec plus de ths_u avis \"\"\"\n",
        "    lu, lg, ld = 0, 0, len(data)\n",
        "    old_lu, old_lg = 1,1\n",
        "    i = 0\n",
        "    while lu != old_lu or lg != old_lg:\n",
        "        rawg = Counter([x[1] for x in data])\n",
        "        rawu = Counter([x[2] for x in data])\n",
        "        old_lu = lu\n",
        "        old_lg = lg\n",
        "        ld = len(data)\n",
        "        lg = len(rawg)\n",
        "        lu = len(rawu)\n",
        "        print(f\"Boucle {i} : Nb games : {lg}, Nb Users : {lu}, sparsity : {ld/(lg*lu)}\")\n",
        "        filtre_g = [k for k,v in rawg.items() if v>ths_g]\n",
        "        filtre_u = [k for k,v in rawu.items() if v>ths_u]\n",
        "        data = [x for x in data if x[1] in filtre_g and x[2] in filtre_u]\n",
        "        i = i +1\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWYbr5Lael2z"
      },
      "outputs": [],
      "source": [
        "#Lecture des données (google colab)\n",
        "# dataraw = [x for x in csv.reader(open(\"./avis.csv\"))]\n",
        "# dic_jeux = dict([(int(x[0]),x[2]) for x in csv.reader(open(\"./jeux.csv\"))])\n",
        "dataraw = [x for x in csv.reader(open(PATH+\"avis.csv\"))]\n",
        "dic_jeux = dict([(int(x[0]),x[2]) for x in csv.reader(open(PATH+\"jeux.csv\"))])\n",
        "# Filtrage des données\n",
        "data_dense = [(int(x[1]),int(x[2]),float(x[6])) for x in filtre(dataraw,30,30)] # on peut jouer avec le filtre\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epLplVu1kGS5"
      },
      "source": [
        "On observe rapidement les caractéristiques du jeu de données restant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3KIaAp-jINF"
      },
      "outputs": [],
      "source": [
        "# Histogramme des notes\n",
        "sns.violinplot([x[2] for x in data_dense])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZWFroIHjdzN"
      },
      "outputs": [],
      "source": [
        "#Histogramme des votes/jeu\n",
        "sns.histplot(Counter([x[0] for x in data_dense]).values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ-eHVBAj-X-"
      },
      "outputs": [],
      "source": [
        "#Histogramme des votes/user\n",
        "sns.histplot(Counter([x[1] for x in data_dense]).values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBHPA45Hf03U"
      },
      "source": [
        "Nous allons définir le dataloader pour ces données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJGnstcsf0MX"
      },
      "outputs": [],
      "source": [
        "\n",
        "class RecoDataset:\n",
        "    def __init__(self,data):\n",
        "        \"\"\" data : (game, user, note) \"\"\"\n",
        "        self.data = data\n",
        "    def __getitem__(self,i):\n",
        "        return self.data[i][0],self.data[i][1],self.data[i][2]\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def prepare_dataloaders(data,split=0.8,note_min=0,note_max=11):\n",
        "    \"\"\"\n",
        "        Normalise les notes entre 0 et 1\n",
        "        Split le dataset en split/1-split. Stratifié par utilisateur\n",
        "        data : (game,user,note)\n",
        "        renvoie les datasets de train, de test, et les correspondances entre index et jeux/utilisateurs\n",
        "    \"\"\"\n",
        "    idx2games = list(set(x[0] for x in data))\n",
        "    idx2users = list(set(x[1] for x in data))\n",
        "    users2idx = dict(zip(idx2users,range(len(idx2users))))\n",
        "    games2idx = dict(zip(idx2games,range(len(idx2games))))\n",
        "    users_notes = dict(zip(range(len(idx2users)), [list() for x in range(len(idx2users))]))\n",
        "    for (g,u,n)  in data:\n",
        "        users_notes[users2idx[u]].append((games2idx[g],n))\n",
        "    train_triplets = []\n",
        "    test_triplets = []\n",
        "    for u,notes in users_notes.items():\n",
        "        shuffle(notes)\n",
        "        train_triplets.extend([(g,u,((n-note_min)/(note_max-note_min))) for (g,n) in notes[:int(split*len(notes))]])\n",
        "        test_triplets.extend([(g,u,((n-note_min)/(note_max-note_min))) for (g,n) in notes[int(split*len(notes)):]])\n",
        "    dtrain = RecoDataset(train_triplets)\n",
        "    dtest = RecoDataset(test_triplets)\n",
        "    return dtrain,dtest,idx2games,idx2users\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4uCLnKEkaBg"
      },
      "source": [
        "Et on construit les dataloaders pour pouvoir travailler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8IjbXL_hh-_"
      },
      "outputs": [],
      "source": [
        "dtrain,dtest, idx2games, idx2users = prepare_dataloaders( data_dense)\n",
        "dl_train = DataLoader(dtrain,batch_size=128,shuffle=True)\n",
        "dl_test = DataLoader(dtest, batch_size=128)\n",
        "dataloaders = {\"train\":dl_train,\"test\":dl_test}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsY3qRadkk5P"
      },
      "source": [
        "Il ne reste plus qu'à définir un modèle pour la prédiction de notes. L'architecture est très simple :\n",
        "\n",
        "\n",
        "*   Une couche d'embedding pour les users de dimension $l$\n",
        "*   Une couche d'embedding pour les jeux de dimension $l$\n",
        "* Les sorties de ces deux couches sont concaténées pour former un vecteur de taille $2*\\ell$. Ce vecteur est ensuite passé à un MLP, qui possède $2*\\ell$ entrées et une sortie (la note prédite) (la couche intermédiaire sera prise arbitrairement de taille $\\ell$).\n",
        "\n",
        "PyTorch fournit le module [`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) pour définir la couche de représentation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7KVnt2YkeW0"
      },
      "outputs": [],
      "source": [
        "\n",
        "class RecoRegNet(nn.Module):\n",
        "    def __init__(self,n_games,n_users,latent_dim=50,act=nn.Tanh):\n",
        "        super().__init__()\n",
        "        # A compléter\n",
        "        #  TODO \n",
        "        pass\n",
        "    def forward(self,igames,iusers):\n",
        "        # A compléter\n",
        "        #  TODO "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tenter de faire passer l'utilisateur 0 + item 0\n",
        "\n",
        "reco = RecoRegNet(10, 10)\n",
        "\n",
        "i = torch.tensor(0).unsqueeze(0)\n",
        "u = torch.tensor(0).unsqueeze(0)\n",
        "\n",
        "print(reco(i, u)) # sortie arbitraire : c'est pour verifier "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J5gJruKliap"
      },
      "source": [
        "Une boucle d'apprentissage très classique pour apprendre le réseau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFjJ5Z4Dlekq"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def train(model, dataloaders, loss,nb_epochs=100,lr=1e-3,early_stop=5):\n",
        "    \"\"\" Boucle d'apprentissage :\n",
        "      * model : modèle à apprendre\n",
        "      * dataloaders : dictionnaire {'train': dataloader de train, 'test' : dataloader de test}\n",
        "      * loss : le coût à optimiser\n",
        "      * nb_epochs : le nombre d'époques\n",
        "      * lr : le learning rate initial\n",
        "      * early_stop : combien d'époques sans améliorations pour s'arrêter\n",
        "    Renvoie le meilleur modèle (selon le dataloader de test)\n",
        "    \"\"\"\n",
        "\n",
        "    model = model.to(device)\n",
        "    opt = optim.Adam(model.parameters(),lr=lr)\n",
        "    # Meilleure loss pour le early stopping\n",
        "    best_l = 1e5\n",
        "    # Compteur d'époques sans améliorations\n",
        "    cpt_early = 0\n",
        "    for epoch in range(nb_epochs):\n",
        "        # On alterne l'évaluation et l'apprentissage\n",
        "        for phase in ['test','train']:\n",
        "            # Coût cumlulé sur tout les exemples\n",
        "            cum_loss = 0\n",
        "            # Accumulateurs des predictions et des vraies notes pour le tracé d'histogramme\n",
        "            all_notes = []\n",
        "            all_ground = []\n",
        "            for games,users,notes in dataloaders[phase]:\n",
        "                # équivalent a with torch.no_grad() pour la phase de test\n",
        "                with torch.set_grad_enabled(phase=='train'):\n",
        "                    # Nécessaire si Dropout ou autres régularisation\n",
        "                    if phase==\"train\":\n",
        "                        model.train()\n",
        "                    else:\n",
        "                        model.eval()\n",
        "                    # Prédiction du batch courant\n",
        "                    yhat = model(games.to(device),users.to(device))\n",
        "                    all_notes.extend(yhat.view(-1).tolist())\n",
        "                    all_ground.extend(notes.view(-1).tolist())\n",
        "                    # Calcul du coût\n",
        "                    l = loss(yhat.view(-1),notes.float().to(device).view(-1))\n",
        "                    # Mise à zéro du gradient\n",
        "                    opt.zero_grad()\n",
        "                    if phase==\"train\":\n",
        "                        # Rétro-propagation\n",
        "                        l.backward()\n",
        "                        opt.step()\n",
        "                    cum_loss += l.item()\n",
        "            writer.add_scalar(f\"loss/{phase}\",cum_loss/len(dataloaders[phase]),epoch)\n",
        "            writer.add_histogram(f\"{phase}/pred\", torch.tensor(all_notes),epoch)\n",
        "            writer.add_histogram(f\"{phase}/ground\", torch.tensor(all_ground),epoch)\n",
        "            print(f\"Phase {phase} : {epoch}/{nb_epochs} {cum_loss/len(dataloaders[phase])}\")\n",
        "            # On compare le meilleur modèle à celui de l'itération courante\n",
        "            # Si meilleur, on sauvegarde\n",
        "            if phase != \"train\":\n",
        "                if best_l>cum_loss/len(dataloaders[phase]):\n",
        "                    best_l = cum_loss/len(dataloaders[phase])\n",
        "                    best_model = copy.deepcopy(model.state_dict())\n",
        "                    print(f\"Best model at epoch {epoch} : {best_l}\")\n",
        "                    early_cpt = 0\n",
        "                else:\n",
        "                    early_cpt += 1\n",
        "        model.eval()\n",
        "        if early_cpt >early_stop:\n",
        "            break\n",
        "    # On récupère le meilleur modèle\n",
        "    model.load_state_dict(best_model)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-oHwbAgnKzl"
      },
      "source": [
        "On définit le modèle et le coût."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QCF6NnbnHaJ"
      },
      "outputs": [],
      "source": [
        "loss = nn.MSELoss()\n",
        "model = RecoRegNet(len(idx2games),len(idx2users),latent_dim=25)\n",
        "notebook.display()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LI8sK8MnQ3K"
      },
      "source": [
        "On apprend le modèle.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GSj64o_nSIy"
      },
      "outputs": [],
      "source": [
        "train(model,dataloaders,loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualisation des embeddings avec TSNE\n",
        "\n",
        "Une des meilleures implémentation de TSNE est disponible dans tensorboard!\n",
        "\n",
        "1. Ajouter les embeddings\n",
        "2. Sélectionner Projector\n",
        "3. Jouer avec les options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.games.weight.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNmhJ9rgnfTP"
      },
      "outputs": [],
      "source": [
        "writer.add_embedding(model.games.weight,metadata=[dic_jeux[idx2games[x]] for x in range(len(idx2games))])\n",
        "#writer.add_embedding(model.games.weight)\n",
        "writer.flush()\n",
        "\n",
        "notebook.display()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction de la triplet loss pour l'apprentissage\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uliSghei0B9B"
      },
      "outputs": [],
      "source": [
        "###  TODO )\",\" TODO \",\\\n",
        "    txt, flags=re.DOTALL))\n",
        "f2.close()\n",
        "\n",
        "### </CORRECTION> ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
