{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation learning & recommender systems\n",
    "\n",
    "In this practical session, we investigate two classical matrix-factorization models and their neural network implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install torch torchvision pytorch-lightning --upgrade\n",
    "#! pip install matplotlib --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data used : [smallest movie-lens dataset](https://grouplens.org/datasets/movielens/)\n",
    "\n",
    "Let's start with a very common dataset describing users, movies & interactions (ratings):\n",
    "\n",
    "![image reco](media/Facto-mat.png)\n",
    "\n",
    "# 1)  Load & Prepare Data\n",
    "\n",
    "To be able to embed the data easily, we need to remap  the user/items between [0->N_User] and [0->N_Items]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0     196      242       3  881250949\n",
       "1     186      302       3  891717742\n",
       "2      22      377       1  878887116\n",
       "3     244       51       2  880606923\n",
       "4     166      346       1  886397596"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "## Load\n",
    "#ratings = pd.read_csv(\"data/ratings.csv\")\n",
    "ratings = pd.read_csv(\"data/ml-100k/u.data\", sep=\"\\t\",dtype=int, names=[\"userId\",\"movieId\", \"rating\", \"timestamp\"])\n",
    "# We use pandas to load the data... And that's it => No pandas requirements for this practical session !\n",
    "\n",
    "ratings.astype({'rating': 'float'},copy=False)\n",
    "ratings.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       0        0       3  881250949\n",
       "1       1        1       3  891717742\n",
       "2       2        2       1  878887116\n",
       "3       3        3       2  880606923\n",
       "4       4        4       1  886397596"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Prepare Data\n",
    "user_map = {user:num for num,user in enumerate(ratings[\"userId\"].unique())}\n",
    "item_map = {item:num for num,item in enumerate(ratings[\"movieId\"].unique())}\n",
    "\n",
    "## Number of users & items\n",
    "num_users = len(user_map)\n",
    "num_items = len(item_map)\n",
    "\n",
    "ratings[\"userId\"] = ratings[\"userId\"].map(user_map)\n",
    "ratings[\"movieId\"] = ratings[\"movieId\"].map(item_map)\n",
    "\n",
    "ratings.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #train:64000, #val:16000 ,#test:20000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating Test/Train as before\n",
    "\n",
    "train_indexes,val_indexes,test_indexes = [],[],[]\n",
    "\n",
    "for index in range(len(ratings)):\n",
    "    if index%5 == 0: # 20% of the data\n",
    "        test_indexes.append(index)\n",
    "    else:\n",
    "        train_indexes.append(index)\n",
    "\n",
    "        \n",
    "shuffle(train_indexes)\n",
    "num_val = int(len(train_indexes)/100*20)\n",
    "val_indexes = train_indexes[:num_val]\n",
    "train_indexes = train_indexes[num_val:]\n",
    "\n",
    "train_ratings = ratings.iloc[train_indexes].copy() # separate data\n",
    "val_ratings = ratings.iloc[val_indexes].copy()\n",
    "test_ratings = ratings.iloc[test_indexes].copy()\n",
    "\n",
    "\n",
    "print(f\" #train:{len(train_ratings)}, #val:{len(val_ratings)} ,#test:{len(test_ratings)}\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82267 823 669 3\n",
      "224 128 185 5\n",
      "26766 487 1028 3\n",
      "53023 587 532 2\n",
      "41402 354 497 4\n",
      "55523 434 797 4\n"
     ]
    }
   ],
   "source": [
    "# USAGE\n",
    "# In what follows, we will browse the tuple this way:\n",
    "cpt = 0\n",
    "for index, uid, mid, r, ts in train_ratings.itertuples():\n",
    "    print(index,uid, mid,r) # remember that indexes were shuffled\n",
    "    cpt+=1\n",
    "    if cpt > 5:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce the baseline model with pytorch's vanilla autograd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal now is to reproduce the following (strong) baseline model from surprise\n",
    "\n",
    " $$\\hat{r}_{ui} = b_{ui} = \\mu + b_u + b_i, \\qquad (\\mu,b_u,b_i) \\in \\mathbb R^3$$\n",
    "\n",
    "[no matrix factorization here, <font color=\"red\">only 3 scalars</font> involved for a prediction $(u,i)$] <BR>\n",
    "[Even $\\mu$ could be computed from the train set, we are going to learn this parameter in the optimization process]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's define the parameters\n",
    "\n",
    "You have many parameters, they are all 1-dimensional:\n",
    "- **mu:** the global mean (1,)\n",
    "- **bu:** the user means (n_users,)\n",
    "- **bi:** the item means (n_items,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.tensor([3.5],requires_grad=True) # activate gradient to be able to learn something\n",
    "bu = [torch.tensor([0.1],requires_grad=True) for _ in range(num_users)]\n",
    "bi = [torch.tensor([0.1],requires_grad=True) for _ in range(num_items)]\n",
    "\n",
    "# # using directly the embedding module it would give:\n",
    "# KEEP custom tensor first => Easier index management\n",
    "# mu = torch.nn.Embedding(1, 1) # only one scalar to learn for the whole set\n",
    "# bu = torch.nn.Embedding(num_users, 1) # one scalar per user\n",
    "# bi = torch.nn.Embedding(num_items, 1) # one scalar per user\n",
    "\n",
    "# # init\n",
    "# torch.nn.init.normal_(mu.weight,3.5,0.001) # almost cst\n",
    "# torch.nn.init.normal_(bu.weight,0.1,0.001) \n",
    "# torch.nn.init.normal_(bi.weight,0.1,0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check the dimensions of the created structures\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then, we define two functions: \n",
    "\n",
    "- `predict(u,i)` : Will return the prediction given the (user,item) pair\n",
    "- `error(pred,real)` : Will return the MSE error of prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (TODO) Predict Function\n",
    "This function should implement this: $\\hat{r}_{ui} = b_{ui} = \\mu + b_u + b_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(u,i):\n",
    "    # build a (simlple) prediction from the above mentioned parameters\n",
    "    if u < num_users: # if user exist:\n",
    "        user_mean = bu[u] # brakets with custom tensors\n",
    "        # user_mean = bu(u) # parentheses with embedding... But also squeeze/unsqueeze required\n",
    "    else:\n",
    "        user_mean = 0 \n",
    "        \n",
    "    if i < num_items: # if item exist:\n",
    "        item_mean = bi[i]\n",
    "    else:\n",
    "        item_mean = 0\n",
    "    \n",
    "    return mu + user_mean + item_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.7000], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# validation on user 0 and item 0 \n",
    "print(predict(0,0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) error function\n",
    "We want to use the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(pred,real):\n",
    "    # define simple MSE (1 line, few chars)\n",
    "    ##  TODO "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The evaluation loop, without any optimization for now\n",
    "\n",
    "Bad results expected... Just to check if we can use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final train error :  1.2960062021330232\n",
      "final val error :  1.3050749529958703\n",
      "final test error :  1.2890999528929592\n"
     ]
    }
   ],
   "source": [
    "train_e = 0\n",
    "for index, uid, mid, r, ts in train_ratings.itertuples(): # elegant way to browse tuples (from pandas structure)\n",
    "    result = predict(uid,mid)\n",
    "    train_e += error(result,r).item()\n",
    "\n",
    "# define the same command for validation, test [copy/past/minor changes on var names]\n",
    "# display the errors    \n",
    "# The 3 errors are likely to be close with no learning step\n",
    "##  TODO "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's optimize the parameters (with SGD)  by slightly modifying the previous loop\n",
    "\n",
    "### (TODO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train error :  1.0149275937308906\n",
      "epoch 0 val error :  0.9548096329354978\n",
      "epoch 0 test error :  0.9430665064536156\n",
      "-----\n",
      "epoch 1 train error :  0.906501407357857\n",
      "epoch 1 val error :  0.9254317481420449\n",
      "epoch 1 test error :  0.9154442776133425\n",
      "-----\n",
      "epoch 2 train error :  0.8841152887978122\n",
      "epoch 2 val error :  0.9126664491395302\n",
      "epoch 2 test error :  0.9026264859532926\n",
      "-----\n",
      "epoch 3 train error :  0.8743678361627621\n",
      "epoch 3 val error :  0.9093964107452017\n",
      "epoch 3 test error :  0.9011910709801301\n",
      "-----\n",
      "epoch 4 train error :  0.8686039850476754\n",
      "epoch 4 val error :  0.9440967657839963\n",
      "epoch 4 test error :  0.9343072900667257\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# parameters' values\n",
    "lr = 0.01\n",
    "batch_size = 32\n",
    "n_epochs = 5\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # loop on the training samples (cf above)\n",
    "    #   prediction\n",
    "    #   error\n",
    "    #   [OPT] error storage to check convergence\n",
    "    #   backward (accumulation)\n",
    "    #   update\n",
    "    #   zero_grad\n",
    "\n",
    "    #  TODO \n",
    "\n",
    "    # Evalaution on the validation set + test set\n",
    "    val_e = 0\n",
    "    for index, uid, mid, r, ts in val_ratings.itertuples():\n",
    "        result = predict(uid,mid)\n",
    "        val_e += error(result,r).item()\n",
    "\n",
    "    print(f\"epoch {epoch} val error : \", val_e/len(val_ratings))\n",
    "\n",
    "    test_e = 0\n",
    "    for index, uid, mid, r, ts in test_ratings.itertuples():\n",
    "        result = predict(uid,mid)\n",
    "        test_e += error(result,r).item()\n",
    "\n",
    "    print(f\"epoch {epoch} test error : \", test_e/len(test_ratings))\n",
    "    print(\"-----\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding module\n",
    "\n",
    "To build a matrix of vectorial representations of dimension $Z$, for instance describing the users, we are going to use a new module called `embedding`:\n",
    "$$ U = \\begin{pmatrix}\\mathbf u_1, \\ldots, \\mathbf u_n\\end{pmatrix}, \\mathbf u \\in \\mathbb R^Z $$ \n",
    "\n",
    "Call for a index, get a $Z$ dimensional representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5: tensor([ 0.6232, -1.2048, -0.4150, -1.1380, -0.7340, -0.0208, -0.2608,  0.8730,\n",
      "        -0.5777, -0.7407], grad_fn=<EmbeddingBackward0>)\n",
      "User 5 & 7: tensor([[ 0.6232, -1.2048, -0.4150, -1.1380, -0.7340, -0.0208, -0.2608,  0.8730,\n",
      "         -0.5777, -0.7407],\n",
      "        [ 1.1847, -0.9924, -0.3560, -0.6786, -0.1207, -0.3784, -1.8091, -1.3639,\n",
      "         -1.6454,  2.3357]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "latent_size = 10\n",
    "nb_users = 100 # arbitrary\n",
    "nb_items = 50\n",
    "users = torch.nn.Embedding(nb_users, latent_size) # random init\n",
    "items = torch.nn.Embedding(nb_items, latent_size) # random init\n",
    "\n",
    "# get representation of user 5:\n",
    "print(\"User 5:\", users(torch.tensor(5))) # WARNING: call for a tensor (not an int)\n",
    "\n",
    "# get representation of user 5 & 7:\n",
    "print(\"User 5 & 7:\", users(torch.tensor([5,7])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5: tensor([-0.0168, -0.0103, -0.0036,  0.0067, -0.0185,  0.0010,  0.0072, -0.0059,\n",
      "        -0.0076,  0.0006], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the embedding with smaller values:\n",
    "\n",
    "torch.nn.init.normal_(users.weight,0,0.01) # apply on the weights\n",
    "\n",
    "# get representation of user 5:\n",
    "print(\"User 5:\", users(torch.tensor(5))) # WARNING: call for a tensor (not an int)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main difficulty = dealing with batch !\n",
    "\n",
    "Based on a very simple matrix factorization formulation:\n",
    "$$ \\hat r = I_i^T U_u $$\n",
    "Are you able to compute $\\hat r$ for a batch of index `ind`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) torch.Size([3])\n",
      "torch.Size([3, 10]) tensor([[-0.0097, -0.0021, -0.0036, -0.0127, -0.0040, -0.0076,  0.0055,  0.0108,\n",
      "         -0.0120,  0.0013],\n",
      "        [-0.0010, -0.0027,  0.0006, -0.0147,  0.0061,  0.0229,  0.0150,  0.0033,\n",
      "          0.0040, -0.0060],\n",
      "        [ 0.0049,  0.0010,  0.0120, -0.0034, -0.0072,  0.0011,  0.0049, -0.0061,\n",
      "         -0.0104, -0.0080]], grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([3]) tensor([ 0.0073, -0.0161, -0.0019], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "ind = torch.tensor([1,2,3])\n",
    "print(ind, ind.size())\n",
    "print(users(ind).size(), users(ind))\n",
    "\n",
    "u = users(ind)\n",
    "i = items(ind)\n",
    "\n",
    "# compute i.T u for all indices\n",
    "# idea to save useless computations:\n",
    "# 1. pairwise multiplication\n",
    "# 2. find the good sum to get correct dimensions (and probably correct results)\n",
    "#  TODO "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific syntax to deal with an undefined number of parameters\n",
    "\n",
    "widely used in python... And in particular in the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4\n",
      "[2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# 1. a fuction return many things (in a tuple)\n",
    "\n",
    "def fonction():\n",
    "    return 1, 2, 3, 4\n",
    "# default behavior => get a tuple:\n",
    "a, b, c, d = fonction()\n",
    "print(a, b, c, d)\n",
    "\n",
    "#2. you can store them in a list (but not the first)\n",
    "_,*res = fonction()\n",
    "\n",
    "# 3. create a new function that takes arbitrary number of parameters:\n",
    "def fonction2(*params):\n",
    "    for p in params:\n",
    "        print(p)\n",
    "\n",
    "fonction2(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  Classic matrix factorisation (called SVD in RecSys) (with mean)\n",
    "\n",
    "To see how it works, we propose to implement a simple SVD:\n",
    "### $$ \\min\\limits_{U,I}\\sum\\limits_{(u,i)} \\underbrace{(r_{ui} -  (I_i^TU_u + \\mu))^2}_\\text{minimization} + \\underbrace{\\lambda(||U_u||^2+||I_u||^2 + \\mu) }_\\text{regularization} $$\n",
    "\n",
    "where prediction is done in the following way:\n",
    "### $$r_{ui} = \\mu + U_u.I_i $$\n",
    "\n",
    "where $\\mu$ is the global mean,  $U_u$ a user embedding and $I_i$ an item embedding\n",
    "\n",
    "### STEPS:\n",
    " To implement such model in pytorch, we need to do multiple things:\n",
    " \n",
    " - (1) model definition\n",
    " - (2) loss function\n",
    " - (3) evaluation\n",
    " - (4) training/eval loop\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### (1) Model definition\n",
    "\n",
    "A model class typically extends `nn.Module`, the Neural network module. It is a convenient way of encapsulating parameters, with helpers for moving them to GPU, exporting, loading, etc.\n",
    "\n",
    "One should define two functions: `__init__` and `forward`.\n",
    "\n",
    "- `__init__` is used to initialize the model parameters\n",
    "- `forward` is the net transformation from input to output. In fact, when doing `moduleClass(input)` you call this method.\n",
    "\n",
    "##### (a) Initialization\n",
    "\n",
    "Our model has different weigths:\n",
    "\n",
    "- the user profiles (also called user embeddings) $U$\n",
    "- the item profiles (also called user embeddings) $I$\n",
    "- the mean bias $\\mu$\n",
    "\n",
    "\n",
    "##### (b) input to output operation\n",
    "Technically, the prediction as defined earlier can be seen as just a dot product between two embeddings $U_u$ and $I_i$ plus the mean rating:\n",
    "\n",
    "- `torch.sum(embed_u*embed_i,1) + self.mean` is equivalent to $r_{ui} = \\mu + U_u.I_i $ \n",
    "- the `.squeeze(1)` operation is a shape operation to remove the dimension 1 (indexing starts at 0) akin to reshaping the matrix from `(batch_size,1,latent_size)` to `(batch_size,latent_size)`\n",
    "- for reference, the inverse operation is `.unsqueeze()`\n",
    "- we return weights to regularize them\n",
    "\n",
    "\n",
    "### (TODO) Just to make sure you were following: complete the following `__init__`and  `forward` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# The model define as a class, inheriting from nn.Module\n",
    "class ClassicMF(torch.nn.Module):\n",
    "    \n",
    "    #(a) Init\n",
    "    def __init__(self,nb_users,nb_items,latent_size):\n",
    "        super(ClassicMF, self).__init__()\n",
    "        # define the embeddings\n",
    "        #   note: the general bias is given with specific syntax\n",
    "        #   note: to define an attribute: self.users = ...\n",
    "        # initialize with std = 0.01\n",
    "\n",
    "        #The mean bias\n",
    "        self.mean = torch.nn.Parameter(torch.FloatTensor(1,).fill_(3)) # another way to activate grad\n",
    "        #  TODO \n",
    "    \n",
    "    # (b) How we compute the prediction (from input to output)\n",
    "    def forward(self, user, item): ## method called when doing ClassicMF(user,item)\n",
    "        # pay attention to the arguments: we have to give indexes\n",
    "        # from the indexes, compute the output\n",
    "        # WARNING : return the embeddings on top of the output to compute the regularization term \n",
    "        #       => 4 outputs expected (the line is given)\n",
    "\n",
    "       \n",
    "        #  TODO \n",
    "        return out, embed_u, embed_i, self.mean  # We return prediction + weights to regularize them\n",
    "       \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2-4) full train loop\n",
    "\n",
    "The train loop is organized around the [Dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) class which Combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset.\n",
    "\n",
    "We just redefine a collate function\n",
    "\n",
    "> collate_fn (callable, optional) – merges a list of samples to form a mini-batch.\n",
    "\n",
    "\n",
    "**NOTE:** The dataset argument can be a list instead of a \"Dataset\" instance (works by duck typing)\n",
    "    \n",
    "\n",
    "##### The train loop sequence is the following:\n",
    "    \n",
    "[Dataset ==Dataloader==> Batch (not prepared) ==collate_fn==> Batch (prepared) ==Model.forward==> Prediction =loss_fn=> loss <-> truth \n",
    "\n",
    "1] PREDICT\n",
    "- (a) The dataloader samples training exemples from the dataset (which is a list)\n",
    "- (b) The collate_fn prepares the minibatch of training exemples\n",
    "- (c) The prediction is made by feeding the minibatch in the model\n",
    "- (d) The loss is computed on the prediction via a loss function\n",
    "\n",
    "2] OPTIMIZE\n",
    "- (e) Gradients are computed by automatic backard propagation\n",
    "- (f) Parameters are updated using computed gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Let's create the datasets following  (Object w/ __getitem__(index) and __len()__, i.e lists ;)\n",
    "prep_train = [(tp.userId,tp.movieId,tp.rating) for tp in train_ratings.itertuples()]\n",
    "prep_val   = [(tp.userId,tp.movieId,tp.rating) for tp in val_ratings.itertuples()]\n",
    "prep_test  = [(tp.userId,tp.movieId,tp.rating) for tp in test_ratings.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(823, 128, 487, 587, 354, 434, 655, 469, 852, 879) (669, 185, 1028, 532, 497, 797, 142, 928, 60, 695) (3, 5, 3, 2, 4, 4, 1, 2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "a,b,c = zip(*prep_train[:10])\n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# HyperParameters\n",
    "n_epochs = 3\n",
    "batch_size = 16\n",
    "num_feat = 25\n",
    "lr = 0.01\n",
    "reg = 0.001\n",
    "\n",
    "\n",
    "#(a) Collate function => Creates tensor batches to feed model during training\n",
    "# It can be removed if data is already tensors (torch or numpy ;)\n",
    "def tuple_batch(l):\n",
    "    '''\n",
    "    input l: list of (user,item,rating tuples)\n",
    "    output: formatted batches (in torch tensors)\n",
    "\n",
    "    takes n-tuples and create batch\n",
    "    text -> seq word #id\n",
    "    '''\n",
    "    users, items, ratings = zip(*l) \n",
    "    users_t = torch.LongTensor(users)\n",
    "    items_t = torch.LongTensor(items)\n",
    "    ratings_t = torch.FloatTensor(ratings)\n",
    "    \n",
    "    return users_t, items_t, ratings_t\n",
    "    \n",
    "\n",
    "\n",
    "#(b) Loss function => Combines MSE and L2\n",
    "def loss_func(pred,ratings_t,reg,*params): # specific syntax \n",
    "    '''\n",
    "    mse loss combined with l2 regularization.\n",
    "    params assumed 2-dimension\n",
    "    '''\n",
    "    mse = F.mse_loss(pred,ratings_t,reduction='sum')\n",
    "    l2 = 0\n",
    "    for p in params: # ranging on all parameters\n",
    "        l2 += torch.mean(p.norm(2,-1))\n",
    "        \n",
    "    return (mse/pred.size(0)) + reg*l2 , mse\n",
    "    \n",
    "#\n",
    "# Training script starts here\n",
    "#    \n",
    "\n",
    "# (a) dataloader will sample data from datasets using collate_fn tuple_batch\n",
    "dataloader_train = DataLoader(prep_train, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=tuple_batch)\n",
    "dataloader_val = DataLoader(prep_val, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=tuple_batch)\n",
    "dataloader_test = DataLoader(prep_test, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=tuple_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model & optimizer\n",
    "\n",
    "model = ClassicMF(num_users,num_items,num_feat)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n",
      "tensor([366, 708,   3, 119, 216, 844, 793,  35,  83, 579, 779, 132, 421, 462,\n",
      "        143, 750])\n",
      "torch.Size([16]) torch.Size([16, 25])\n",
      "tensor([3.0002, 3.0000, 3.0004, 2.9992, 2.9994, 2.9997, 2.9999, 3.0002, 3.0002,\n",
      "        2.9998, 3.0004, 3.0002, 2.9998, 2.9987, 2.9999, 2.9996],\n",
      "       grad_fn=<AddBackward0>)\n",
      "3\n",
      "torch.Size([16, 25])\n",
      "(tensor(1.5659, grad_fn=<AddBackward0>), tensor(25.0054, grad_fn=<MseLossBackward0>))\n"
     ]
    }
   ],
   "source": [
    "## INTERMEDIATE BOX for in depth understanding\n",
    "\n",
    "# inference & parameter retrieving (if your forward is defined as expected)\n",
    "users_t,items_t,ratings_t = next(iter(dataloader_train)) # retrieve first batch\n",
    "# check dim\n",
    "print(users_t.size()) # batch\n",
    "print(users_t)\n",
    "\n",
    "# output of the forward step:\n",
    "pred, embed_u, embed_i, mu = model(users_t,items_t)\n",
    "print(pred.size(), embed_u.size()) # batch\n",
    "print(pred) # Current predictions for the batch\n",
    "\n",
    "# alternative advanced syntax\n",
    "pred, *params = model(users_t,items_t) # param is a list !!\n",
    "print(len(params)) \n",
    "print(params[0].size()) # params[0] corresponds to embed_u\n",
    "\n",
    "# idea: retrieving the list of parameter... And then transmit the list to loss_func without unpacking\n",
    "print(loss_func(pred,ratings_t,reg,*params))    # yhat, y, lambda_reg, all_params\n",
    "                                                # return mse + regul, mse (sum not the mean)\n",
    "\n",
    "# we can apply backward on what we want...\n",
    "                                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "epoch 0 mse (train/val/test) 1.187 / 1.046 / 1.025\n",
      "-------------------------\n",
      "epoch 1 mse (train/val/test) 0.914 / 0.932 / 0.912\n",
      "-------------------------\n",
      "epoch 2 mse (train/val/test) 0.774 / 0.895 / 0.878\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Train loop (epoch)\n",
    "#   loop over the dataloader\n",
    "#       forward (+get the parameters)\n",
    "#       loss\n",
    "#       backward\n",
    "#       optim\n",
    "#   compute mse on validation & test\n",
    "#   display losses for epoch e\n",
    "#\n",
    "\n",
    "## TODO \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Your turn from scratch) Koren 2009 model:\n",
    "\n",
    "Here, this model simply adds a bias for each user and for each item\n",
    "\n",
    "### $$ \\min\\limits_{U,I}\\sum\\limits_{(u,i)} \\underbrace{(r_{ui} -  (I_i^TU_u + \\mu+ \\mu_i+\\mu_u))^2}_\\text{minimization} + \\underbrace{\\lambda(||U_u||^2+||I_u||^2 + \\mu  + \\mu_i+\\mu_u) }_\\text{regularization} $$\n",
    "\n",
    "\n",
    "### $$r_{ui} = \\mu + \\mu_i + \\mu_u + U_u.I_i $$\n",
    "\n",
    "### TODO:\n",
    "\n",
    "- (a) complete the model initialization\n",
    "- (b) complete the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  TODO "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) Here, train loop stays the same, you only have to change the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 16\n",
    "num_feat = 25\n",
    "lr = 0.01\n",
    "reg = 0.001\n",
    "\n",
    "# note: previous loss function should be robust to the new model thanks to advanced syntax :)\n",
    "\n",
    "model =  KorenMF(num_users,num_items,num_feat)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# same loop as before\n",
    "#  TODO \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Optional part] How to complete this series of experiments\n",
    "\n",
    "### Visualization\n",
    "\n",
    "Use tsne to display embedding\n",
    "* could be done with sklearn [link](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)\n",
    "* often done with tensorboard in deep applications\n",
    "\n",
    "\n",
    "### Regularization\n",
    "\n",
    "Exploit side informations to regularize the profiles:\n",
    "* Users from the same age category are supposed to have closer representations, Movies from the same genre, etc...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       2\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "938     5\n",
       "939     4\n",
       "940     5\n",
       "941    11\n",
       "942     5\n",
       "Name: prof, Length: 943, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load side informations\n",
    "uinfo = pd.read_csv(\"data/ml-100k/u.user\", sep=\"|\", names=[\"userId\",\"age\", \"genre\", \"prof\",\"zip\"])\n",
    "uinfo.head(5)\n",
    "\n",
    "# WARNING: we changed the definition of ids => make ids consistent\n",
    "uinfo[\"userId\"].map(user_map) # using the same dictionary\n",
    "genre_map = {g:num for num,g in enumerate(uinfo[\"genre\"].unique())}\n",
    "uinfo[\"genre\"].map(genre_map) \n",
    "prof_map = {p:num for num,p in enumerate(uinfo[\"prof\"].unique())}\n",
    "uinfo[\"prof\"].map(prof_map) \n",
    "# age cat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction du sujet à partir de la correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  TODO )\",\" TODO \",\\\n",
    "    txt, flags=re.DOTALL))\n",
    "f2.close()\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "902a52bcf4503a473db011f1937bdfe17613b08622219712e0110e48c4958c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
