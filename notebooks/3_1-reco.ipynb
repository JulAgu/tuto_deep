{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation learning & recommender systems\n",
    "\n",
    "In this practical session, we investigate two classical matrix-factorization models and their neural network implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install torch torchvision pytorch-lightning --upgrade\n",
    "#! pip install matplotlib --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data used : [smallest movie-lens dataset](https://grouplens.org/datasets/movielens/)\n",
    "\n",
    "Let's start with a very common dataset describing users, movies & interactions (ratings):\n",
    "\n",
    "![image reco](media/Facto-mat.png)\n",
    "\n",
    "# 1)  Load & Prepare Data\n",
    "\n",
    "To be able to embed the data easily, we need to remap  the user/items between [0->N_User] and [0->N_Items]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0     196      242       3  881250949\n",
       "1     186      302       3  891717742\n",
       "2      22      377       1  878887116\n",
       "3     244       51       2  880606923\n",
       "4     166      346       1  886397596"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "## Load\n",
    "#ratings = pd.read_csv(\"data/ratings.csv\")\n",
    "ratings = pd.read_csv(\"data/ml-100k/u.data\", sep=\"\\t\",dtype=int, names=[\"userId\",\"movieId\", \"rating\", \"timestamp\"])\n",
    "ratings.astype({'rating': 'float'},copy=False)\n",
    "ratings.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       0        0       3  881250949\n",
       "1       1        1       3  891717742\n",
       "2       2        2       1  878887116\n",
       "3       3        3       2  880606923\n",
       "4       4        4       1  886397596"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Prepare Data\n",
    "user_map = {user:num for num,user in enumerate(ratings[\"userId\"].unique())}\n",
    "item_map = {item:num for num,item in enumerate(ratings[\"movieId\"].unique())}\n",
    "\n",
    "## Number of users & items\n",
    "num_users = len(user_map)\n",
    "num_items = len(item_map)\n",
    "\n",
    "ratings[\"userId\"] = ratings[\"userId\"].map(user_map)\n",
    "ratings[\"movieId\"] = ratings[\"movieId\"].map(item_map)\n",
    "\n",
    "ratings.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #train:64000, #val:16000 ,#test:20000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating Test/Train as before\n",
    "\n",
    "train_indexes,val_indexes,test_indexes = [],[],[]\n",
    "\n",
    "for index in range(len(ratings)):\n",
    "    if index%5 == 0: # 20% of the data\n",
    "        test_indexes.append(index)\n",
    "    else:\n",
    "        train_indexes.append(index)\n",
    "\n",
    "        \n",
    "shuffle(train_indexes)\n",
    "num_val = int(len(train_indexes)/100*20)\n",
    "val_indexes = train_indexes[:num_val]\n",
    "train_indexes = train_indexes[num_val:]\n",
    "\n",
    "train_ratings = ratings.iloc[train_indexes].copy() # separate data\n",
    "val_ratings = ratings.iloc[val_indexes].copy()\n",
    "test_ratings = ratings.iloc[test_indexes].copy()\n",
    "\n",
    "\n",
    "print(f\" #train:{len(train_ratings)}, #val:{len(val_ratings)} ,#test:{len(test_ratings)}\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7048 35 1076 3\n",
      "23124 318 229 5\n",
      "76987 620 25 3\n",
      "48022 507 1449 4\n",
      "96463 940 483 2\n",
      "59973 674 158 4\n"
     ]
    }
   ],
   "source": [
    "# USAGE\n",
    "# In what follows, we will browse the tuple this way:\n",
    "cpt = 0\n",
    "for index, uid, mid, r, ts in train_ratings.itertuples():\n",
    "    print(index,uid, mid,r) # remember that indexes were shuffled\n",
    "    cpt+=1\n",
    "    if cpt > 5:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce the baseline model with pytorch's vanilla autograd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal now is to reproduce the following (strong) baseline model from surprise\n",
    "\n",
    " $$\\hat{r}_{ui} = b_{ui} = \\mu + b_u + b_i$$\n",
    "\n",
    "[no matrix factorization here, only 3 scalars involved for a prediction $(u,i)$] <BR>\n",
    "[Even $\\mu$ could be computed from the train set, we are going to learn this parameter in the optimization process]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's define the parameters\n",
    "\n",
    "You have many parameters, they are all 1-dimensional:\n",
    "- **mu:** the global mean (1,)\n",
    "- **bu:** the user means (n_users,)\n",
    "- **bi:** the item means (n_items,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.tensor([3.5],requires_grad=True) # activate gradient to be able to learn something\n",
    "bu = [torch.tensor([0.1],requires_grad=True) for _ in range(num_users)]\n",
    "bi = [torch.tensor([0.1],requires_grad=True) for _ in range(num_items)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then, we define two functions: \n",
    "\n",
    "- `predict(u,i)` : Will return the prediction given the (user,item) pair\n",
    "- `error(pred,real)` : Will return the MSE error of prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (TODO) Predict Function\n",
    "This function should implement this: $\\hat{r}_{ui} = b_{ui} = \\mu + b_u + b_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(u,i):\n",
    "    # build a (simlple) prediction from the above mentioned parameters\n",
    "    ##  TODO "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) error function\n",
    "We want to use the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(pred,real):\n",
    "    # define simple MSE\n",
    "    ##  TODO "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The evaluation loop, without any optimization for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final train error :  1.297749952620943\n",
      "final val error :  1.2980999510441906\n",
      "final test error :  1.2890999528929592\n"
     ]
    }
   ],
   "source": [
    "train_e = 0\n",
    "for index, uid, mid, r, ts in train_ratings.itertuples(): # elegant way to browse tuples (from pandas structure)\n",
    "    result = predict(uid,mid)\n",
    "    train_e += error(result,r).item()\n",
    "\n",
    "# define the same command for validation, test\n",
    "# display the errors    \n",
    "# The 3 errors are likely to be close\n",
    "##  TODO "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's optimize the parameters (with SGD)  by slightly modifying the previous loop\n",
    "\n",
    "### (TODO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train error :  1.115951048684718\n",
      "epoch 0 val error :  1.0075381769452092\n",
      "epoch 0 test error :  1.0171096366554184\n",
      "-----\n",
      "epoch 1 train error :  0.983901562118671\n",
      "epoch 1 val error :  0.9854860890130736\n",
      "epoch 1 test error :  1.0000026043019827\n",
      "-----\n",
      "epoch 2 train error :  0.9378580559998576\n",
      "epoch 2 val error :  0.9336627769944015\n",
      "epoch 2 test error :  0.9482141569386194\n",
      "-----\n",
      "epoch 3 train error :  0.9197446114585628\n",
      "epoch 3 val error :  0.9279990462217967\n",
      "epoch 3 test error :  0.9425050851423508\n",
      "-----\n",
      "epoch 4 train error :  0.9064893474218316\n",
      "epoch 4 val error :  0.9654338803511199\n",
      "epoch 4 test error :  0.9749095367468712\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# parameters' values\n",
    "lr = 0.01\n",
    "batch_size = 32\n",
    "n_epochs = 5\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # loop on the training samples\n",
    "    #   prediction\n",
    "    #   error\n",
    "    #   backward (accumulation)\n",
    "    #   update\n",
    "    #   zero_grad\n",
    "\n",
    "    #  TODO \n",
    "\n",
    "    # Evalaution on the validation set + test set\n",
    "    val_e = 0\n",
    "    for index, uid, mid, r, ts in val_ratings.itertuples():\n",
    "        result = predict(uid,mid)\n",
    "        val_e += error(result,r).item()\n",
    "\n",
    "    print(f\"epoch {epoch} val error : \", val_e/len(val_ratings))\n",
    "\n",
    "    test_e = 0\n",
    "    for index, uid, mid, r, ts in test_ratings.itertuples():\n",
    "        result = predict(uid,mid)\n",
    "        test_e += error(result,r).item()\n",
    "\n",
    "    print(f\"epoch {epoch} test error : \", test_e/len(test_ratings))\n",
    "    print(\"-----\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding module\n",
    "\n",
    "To build a matrix of vectorial representations of dimension $Z$, for instance describing the users, we are going to use a new module called `embedding`:\n",
    "$$ U = \\begin{pmatrix}\\mathbf u_1, \\ldots, \\mathbf u_n\\end{pmatrix}, \\mathbf u \\in \\mathbb R^Z $$ \n",
    "\n",
    "Call for a index, get a $Z$ dimensional representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5: tensor([-0.5676,  0.2476, -0.8242,  0.1961,  1.6378, -0.4224, -1.1606, -0.2568,\n",
      "        -1.0188, -1.2670], grad_fn=<EmbeddingBackward0>)\n",
      "User 5 & 7: tensor([[-0.5676,  0.2476, -0.8242,  0.1961,  1.6378, -0.4224, -1.1606, -0.2568,\n",
      "         -1.0188, -1.2670],\n",
      "        [-0.3021, -0.4939, -1.2852, -1.2867, -0.3640,  0.8740,  0.0207, -0.8172,\n",
      "         -0.0129,  1.0974]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "latent_size = 10\n",
    "nb_users = 100\n",
    "users = torch.nn.Embedding(nb_users, latent_size) # random init\n",
    "\n",
    "# get representation of user 5:\n",
    "print(\"User 5:\", users(torch.tensor(5))) # WARNING: call for a tensor (not an int)\n",
    "\n",
    "# get representation of user 5 & 7:\n",
    "print(\"User 5 & 7:\", users(torch.tensor([5,7])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5: tensor([-0.0060, -0.0039,  0.0131,  0.0117, -0.0164, -0.0036,  0.0154,  0.0065,\n",
      "         0.0116,  0.0018], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the embedding with smaller values:\n",
    "\n",
    "torch.nn.init.normal_(users.weight,0,0.01) # apply on the weights\n",
    "\n",
    "# get representation of user 5:\n",
    "print(\"User 5:\", users(torch.tensor(5))) # WARNING: call for a tensor (not an int)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  Classic matrix factorisation (called SVD in RecSys) (with mean)\n",
    "\n",
    "To see how it works, we propose to implement a simple SVD:\n",
    "### $$ \\min\\limits_{U,I}\\sum\\limits_{(u,i)} \\underbrace{(r_{ui} -  (I_i^TU_u + \\mu))^2}_\\text{minimization} + \\underbrace{\\lambda(||U_u||^2+||I_u||^2 + \\mu) }_\\text{regularization} $$\n",
    "\n",
    "where prediction is done in the following way:\n",
    "### $$r_{ui} = \\mu + U_u.I_i $$\n",
    "\n",
    "where $\\mu$ is the global mean,  $U_u$ a user embedding and $I_i$ an item embedding\n",
    "\n",
    "### STEPS:\n",
    " To implement such model in pytorch, we need to do multiple things:\n",
    " \n",
    " - (1) model definition\n",
    " - (2) loss function\n",
    " - (3) evaluation\n",
    " - (4) training/eval loop\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### (1) Model definition\n",
    "\n",
    "A model class typically extends `nn.Module`, the Neural network module. It is a convenient way of encapsulating parameters, with helpers for moving them to GPU, exporting, loading, etc.\n",
    "\n",
    "One should define two functions: `__init__` and `forward`.\n",
    "\n",
    "- `__init__` is used to initialize the model parameters\n",
    "- `forward` is the net transformation from input to output. In fact, when doing `moduleClass(input)` you call this method.\n",
    "\n",
    "##### (a) Initialization\n",
    "\n",
    "Our model has different weigths:\n",
    "\n",
    "- the user profiles (also called user embeddings) $U$\n",
    "- the item profiles (also called user embeddings) $I$\n",
    "- the mean bias $\\mu$\n",
    "\n",
    "\n",
    "##### (b) input to output operation\n",
    "Technically, the prediction as defined earlier can be seen as just a dot product between two embeddings $U_u$ and $I_i$ plus the mean rating:\n",
    "\n",
    "- `torch.sum(embed_u*embed_i,1) + self.mean` is equivalent to $r_{ui} = \\mu + U_u.I_i $ \n",
    "- the `.squeeze(1)` operation is a shape operation to remove the dimension 1 (indexing starts at 0) akin to reshaping the matrix from `(batch_size,1,latent_size)` to `(batch_size,latent_size)`\n",
    "- for reference, the inverse operation is `.unsqueeze()`\n",
    "- we return weights to regularize them\n",
    "\n",
    "\n",
    "### (TODO) Just to make sure you were following: complete the following `__init__`and  `forward` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# The model define as a class, inheriting from nn.Module\n",
    "class ClassicMF(torch.nn.Module):\n",
    "    \n",
    "    #(a) Init\n",
    "    def __init__(self,nb_users,nb_items,latent_size):\n",
    "        super(ClassicMF, self).__init__()\n",
    "        # define the embeddings\n",
    "        #   note: to define an attribute: self.users = ...\n",
    "        # initialize with std = 0.01\n",
    "        # define mu & initialize = 3\n",
    "\n",
    "        #  TODO \n",
    "    \n",
    "    # (b) How we compute the prediction (from input to output)\n",
    "    def forward(self, user, item): ## method called when doing ClassicMF(user,item)\n",
    "        # pay attention to the arguments: we have to give indexes\n",
    "        # from the indexes, compute the output\n",
    "        # WARNING: print self.users(user) once to understand which dimension to squeeze\n",
    "        # WARNING (2): return the embeddings on top of the output to compute the regularization term => 4 outputs expected\n",
    "\n",
    "        #  TODO \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2-4) full train loop\n",
    "\n",
    "The train loop is organized around the [Dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) class which Combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset.\n",
    "\n",
    "We just redefine a collate function\n",
    "\n",
    "> collate_fn (callable, optional) – merges a list of samples to form a mini-batch.\n",
    "\n",
    "\n",
    "**NOTE:** The dataset argument can be a list instead of a \"Dataset\" instance (works by duck typing)\n",
    "    \n",
    "\n",
    "##### The train loop sequence is the following:\n",
    "    \n",
    "[Dataset ==Dataloader==> Batch (not prepared) ==collate_fn==> Batch (prepared) ==Model.forward==> Prediction =loss_fn=> loss <-> truth \n",
    "\n",
    "1] PREDICT\n",
    "- (a) The dataloader samples training exemples from the dataset (which is a list)\n",
    "- (b) The collate_fn prepares the minibatch of training exemples\n",
    "- (c) The prediction is made by feeding the minibatch in the model\n",
    "- (d) The loss is computed on the prediction via a loss function\n",
    "\n",
    "2] OPTIMIZE\n",
    "- (e) Gradients are computed by automatic backard propagation\n",
    "- (f) Parameters are updated using computed gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Let's create the datasets following  (Object w/ __getitem__(index) and __len()__, i.e lists ;)\n",
    "prep_train = [(tp.userId,tp.movieId,tp.rating) for tp in train_ratings.itertuples()]\n",
    "prep_val   = [(tp.userId,tp.movieId,tp.rating) for tp in val_ratings.itertuples()]\n",
    "prep_test  = [(tp.userId,tp.movieId,tp.rating) for tp in test_ratings.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 318, 620, 507, 940, 674, 912, 428, 145, 14) (1076, 229, 25, 1449, 483, 158, 211, 1114, 356, 516) (3, 5, 3, 4, 2, 4, 4, 5, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "a,b,c = zip(*prep_train[:10])\n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# HyperParameters\n",
    "n_epochs = 3\n",
    "batch_size = 16\n",
    "num_feat = 25\n",
    "lr = 0.01\n",
    "reg = 0.001\n",
    "\n",
    "\n",
    "#(b) Collate function => Creates tensor batches to feed model during training\n",
    "# It can be removed if data is already tensors (torch or numpy ;)\n",
    "def tuple_batch(l):\n",
    "    '''\n",
    "    input l: list of (user,item,rating tuples)\n",
    "    output: formatted batches (in torch tensors)\n",
    "\n",
    "    takes n-tuples and create batch\n",
    "    text -> seq word #id\n",
    "    '''\n",
    "    users, items, ratings = zip(*l) \n",
    "    users_t = torch.LongTensor(users)\n",
    "    items_t = torch.LongTensor(items)\n",
    "    ratings_t = torch.FloatTensor(ratings)\n",
    "    \n",
    "    return users_t, items_t, ratings_t\n",
    "    \n",
    "\n",
    "\n",
    "#(d) Loss function => Combines MSE and L2\n",
    "def loss_func(pred,ratings_t,reg,*params): # specific syntax (cf details in the next box)\n",
    "    '''\n",
    "    mse loss combined with l2 regularization.\n",
    "    params assumed 2-dimension\n",
    "    '''\n",
    "    mse = F.mse_loss(pred,ratings_t,reduction='sum')\n",
    "    l2 = 0\n",
    "    for p in params: # ranging on all parameters\n",
    "        l2 += torch.mean(p.norm(2,-1))\n",
    "        \n",
    "    return (mse/pred.size(0)) + reg*l2 , mse\n",
    "    \n",
    "#\n",
    "# Training script starts here\n",
    "#    \n",
    "\n",
    "# (a) dataloader will sample data from datasets using collate_fn tuple_batch\n",
    "dataloader_train = DataLoader(prep_train, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=tuple_batch)\n",
    "dataloader_val = DataLoader(prep_val, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=tuple_batch)\n",
    "dataloader_test = DataLoader(prep_test, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=tuple_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model & optimizer\n",
    "\n",
    "model = ClassicMF(num_users,num_items,num_feat)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n",
      "tensor([451, 869, 224, 545, 835, 837, 776, 608, 523, 100, 310, 758, 364,  92,\n",
      "        688,  54])\n",
      "torch.Size([16]) torch.Size([16, 25])\n",
      "tensor([3.0001, 3.0002, 2.9993, 2.9998, 3.0002, 2.9998, 3.0006, 2.9993, 3.0001,\n",
      "        3.0001, 2.9997, 2.9994, 2.9998, 2.9993, 2.9998, 2.9997],\n",
      "       grad_fn=<AddBackward0>)\n",
      "3\n",
      "torch.Size([16, 25])\n",
      "(tensor(1.6909, grad_fn=<AddBackward0>), tensor(27.0042, grad_fn=<MseLossBackward0>))\n"
     ]
    }
   ],
   "source": [
    "## INTERMEDIATE BOX for in depth understanding\n",
    "\n",
    "# inference & parameter retrieving (if your forward is defined as expected)\n",
    "users_t,items_t,ratings_t = next(iter(dataloader_train)) # retrieve first batch\n",
    "# check dim\n",
    "print(users_t.size()) # batch\n",
    "print(users_t)\n",
    "\n",
    "# output of the forward step:\n",
    "pred, embed_u, embed_i, mu = model(users_t,items_t)\n",
    "print(pred.size(), embed_u.size()) # batch\n",
    "print(pred) # Current predictions for the batch\n",
    "\n",
    "# alternative advanced syntax\n",
    "pred, *params = model(users_t,items_t) # param is a list !!\n",
    "print(len(params)) \n",
    "print(params[0].size()) # params[0] corresponds to embed_u\n",
    "\n",
    "# idea: retrieving the list of parameter... And then transmit the list to loss_func without unpacking\n",
    "print(loss_func(pred,ratings_t,reg,*params))    # yhat, y, lambda_reg, all_params\n",
    "                                                # return mse + regul, mse (sum not the mean)\n",
    "\n",
    "# we can apply backward on what we want...\n",
    "                                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "epoch 0 mse (train/val/test) 1.194 / 1.024 / 1.019\n",
      "-------------------------\n",
      "epoch 1 mse (train/val/test) 0.91 / 0.91 / 0.904\n",
      "-------------------------\n",
      "epoch 2 mse (train/val/test) 0.774 / 0.876 / 0.874\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Train loop (epoch)\n",
    "#   loop over the dataloader\n",
    "#       forward (+get the parameters)\n",
    "#       loss\n",
    "#       backward\n",
    "#       optim\n",
    "#   compute mse on validation & test\n",
    "#   display losses for epoch e\n",
    "#\n",
    "\n",
    "## TODO \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Your turn from scratch) Koren 2009 model:\n",
    "\n",
    "Here, this model simply adds a bias for each user and for each item\n",
    "\n",
    "### $$ \\min\\limits_{U,I}\\sum\\limits_{(u,i)} \\underbrace{(r_{ui} -  (I_i^TU_u + \\mu+ \\mu_i+\\mu_u))^2}_\\text{minimization} + \\underbrace{\\lambda(||U_u||^2+||I_u||^2 + \\mu  + \\mu+ \\mu_i+\\mu_u) }_\\text{regularization} $$\n",
    "\n",
    "\n",
    "### $$r_{ui} = \\mu + \\mu_i + \\mu_u + U_u.I_i $$\n",
    "\n",
    "### TODO:\n",
    "\n",
    "- (a) complete the model initialization\n",
    "- (b) complete the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  TODO "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) Here, train loop stays the same, you only have to change the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 16\n",
    "num_feat = 25\n",
    "lr = 0.01\n",
    "reg = 0.001\n",
    "\n",
    "# note: previous loss function should be robust to the new model thanks to advanced syntax :)\n",
    "\n",
    "model =  KorenMF(num_users,num_items,num_feat)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# same loop as before\n",
    "#  TODO \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Optional part] How to complete this series of experiments\n",
    "\n",
    "### Visualization\n",
    "\n",
    "Use tsne to display embedding\n",
    "* could be done with sklearn [link](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)\n",
    "* often done with tensorboard in deep applications\n",
    "\n",
    "\n",
    "### Regularization\n",
    "\n",
    "Exploit side informations to regularize the profiles:\n",
    "* Users from the same age category are supposed to have closer representations, Movies from the same genre, etc...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       2\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "938     5\n",
       "939     4\n",
       "940     5\n",
       "941    11\n",
       "942     5\n",
       "Name: prof, Length: 943, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load side informations\n",
    "uinfo = pd.read_csv(\"data/ml-100k/u.user\", sep=\"|\", names=[\"userId\",\"age\", \"genre\", \"prof\",\"zip\"])\n",
    "uinfo.head(5)\n",
    "\n",
    "# WARNING: we changed the definition of ids => make ids consistent\n",
    "uinfo[\"userId\"].map(user_map) # using the same dictionary\n",
    "genre_map = {g:num for num,g in enumerate(uinfo[\"genre\"].unique())}\n",
    "uinfo[\"genre\"].map(genre_map) \n",
    "prof_map = {p:num for num,p in enumerate(uinfo[\"prof\"].unique())}\n",
    "uinfo[\"prof\"].map(prof_map) \n",
    "# age cat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction du sujet à partir de la correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  TODO )\",\" TODO \",\\\n",
    "    txt, flags=re.DOTALL))\n",
    "f2.close()\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "902a52bcf4503a473db011f1937bdfe17613b08622219712e0110e48c4958c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
