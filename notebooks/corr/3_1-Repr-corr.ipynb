{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "convinced-ceramic",
   "metadata": {},
   "source": [
    "# Apprentissage de représentation, Texte et recommendation \n",
    "\n",
    "## Partie A : Prise en main TorchText et représentation\n",
    "\n",
    "Vincent Guigue, à partir des supports de:\n",
    "\n",
    "Nicolas Baskiotis (nicolas.baskiotis@sorbonne-univeriste.fr) Benjamin Piwowarski (benjamin.piwowarski@sorbonne-universite.fr) -- MLIA/ISIR, Sorbonne Université"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-population",
   "metadata": {},
   "source": [
    "<a href=https://pytorch.org/text/stable/index.html> **TorchText** </a> est le module de pytorch pour le pré-traitement du texte. Il permet entre autre les opérations usuelles de pré-traitement et de tokenization, et contient beaucoup d'autres outils adaptés au deep. Assurez vous d'avoir la dernière version d'installée (>=0.11.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "selected-night",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-22c7fa9ba7e7b64f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-22c7fa9ba7e7b64f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6010;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "assert torchtext.__version__ >= \"0.11.0\"\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "TB_PATH = \"/tmp/logs/module3\"\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir  {TB_PATH}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-speaking",
   "metadata": {},
   "source": [
    "# Représentation en espace continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-passport",
   "metadata": {},
   "source": [
    "L'objectif de cette partie est  d'explorer et de comprendre la notion de représentation en espace continu (*embedding*). Il s'agit de *projeter* des objets pour la plupart du temps discrets (des mots, des index d'utilisateurs ou d'items) dans un espace continue d'une dimension de représentation choisie. Une bonne représentation permet entre autre d'exprimer une *sémantique* sur les objets projetés. Elle est souvent  construite à partir d'une notion de similarité qui doit être préservée en termes de distance dans l'espace projeté : les objets qui sont *proches* en un sens défini doivent également être proches dans l'espace de représentation. Ces *nouvelles* représentations peuvent ensuite être utilisée comme nouvelle description de l'objet d'étude dans une multitude de tâches (classification, clustering, traduction, ...).  Plus récemment, on utilise ce que l'on appelle un *apprentissage end-to-end*, c'est-à-dire que les représentations sont apprises en même temps que le réseau chargé d'une tâche en question. En effet, d'un point de vue réseau de neurones, un apprentissage de représentation n'est rien d'autre qu'une couche linéaire d'un espace de dimenion le nombre d'objet vers l'espace de représentation : un index est attribué à chaque objet arbitrairement et il est ensuite encodé en vecteur *one-hot* : un vecteur de la taille le nombre d'objet qui ne contient que des 0 sauf à l'index de l'objet qui vaut 1. Les poids du réseau linéaire sont ainsi les coordonnées vectorielles de chaque objet dans le nouvel espace de représentation. Pytorch a un module dédié : <a href=https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html> le **nn.Embedding**</a>.\n",
    "\n",
    "\n",
    "**Remarque importante :** lorsque la dimension est grande, la distance euclidienne n'est pas significative. On préfère utiliser la similarité *cosine* : $cosine(\\mathbf{x},\\mathbf{z}) = \\frac{\\langle \\mathbf{x},\\mathbf{z}\\rangle}{\\|\\mathbf{x}\\|\\|\\mathbf{y}\\|}$ qui dénote l'angle entre les deux vecteurs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-humanity",
   "metadata": {},
   "source": [
    "## Chargement et pré-processing des données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-albania",
   "metadata": {},
   "source": [
    "Nous utiliserons l'exemple suivant : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "first-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemple = [\n",
    "    'the cat is on the bank',\n",
    "    'the bank near the black cat',\n",
    "    'a big dog with a ball',\n",
    "    'dog and cat are not similar',\n",
    "    'dog and child with a ball',\n",
    "    'white bird on a big tree']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-fever",
   "metadata": {},
   "source": [
    "Il faut bien sûr toujours pré-processer le texte. **Torchtext** contient différents moteurs de pré-processing (dont ceux de **spacy**, cf <a href=https://pytorch.org/text/stable/data_utils.html> la doc </a>). \n",
    "\n",
    "La classe de base qui permet de manipuler un corpus est la classe <a href=https://pytorch.org/text/stable/vocab.html> **Vocab**</a>. Elle permet de faire le lien entre un token et son index par l'intermédiaire d'un dictionnaire *string -> idx* et d'une liste qui permet de récuperer le token correspondant à un indice. Un objet <a href=https://pytorch.org/text/stable/vocab.html#vectors> Vectors</a> permet de faire le lien entre un indice et la représentation vectorielle du token correspondant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "musical-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On récupère un tokenizer\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "tokens = [tokenizer(doc) for doc in exemple]\n",
    "## On construit le vocabulaire associé. \n",
    "## Il est possible de filtrer en fonction de la fréquence et d'ajouter des tokens spéciaux : \n",
    "## <pad> pour un caractère vide et <oov> pour un mot qui n'apparaît pas dans le vocabulaire.\n",
    "vocab = torchtext.vocab.build_vocab_from_iterator(tokens,min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "egyptian-hammer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['charngram.100d', 'fasttext.en.300d', 'fasttext.simple.300d', 'glove.42B.300d', 'glove.840B.300d', 'glove.twitter.27B.25d', 'glove.twitter.27B.50d', 'glove.twitter.27B.100d', 'glove.twitter.27B.200d', 'glove.6B.50d', 'glove.6B.100d', 'glove.6B.200d', 'glove.6B.300d'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/wiki.simple.vec: 293MB [00:15, 19.3MB/s]                              \n",
      "  0%|          | 0/111051 [00:00<?, ?it/s]Skipping token b'111051' with 1-dimensional vector [b'300']; likely a header\n",
      "100%|██████████| 111051/111051 [00:07<00:00, 15642.76it/s]\n"
     ]
    }
   ],
   "source": [
    "## On affiche toutes les représentations disponibles\n",
    "print(torchtext.vocab.pretrained_aliases.keys())\n",
    "## On prend une des  plus légères\n",
    "fasttext = torchtext.vocab.FastText('simple')\n",
    "## On construit notre propre vecteur qui correspond à notre vocabulaire.\n",
    "vectors = []\n",
    "for s in vocab.get_itos():\n",
    "    vectors.append(fasttext.vectors[fasttext.stoi[s]])\n",
    "vectors = torch.stack(vectors)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "measured-niger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping vocabulaire -> identifiant [('</s>', 0), ('.', 1), (',', 2), ('the', 3), ('of', 4), (\"'\", 5), ('in', 6), ('-', 7), ('and', 8), (')', 9), ('(', 10), ('a', 11), ('to', 12), ('is', 13), ('was', 14), ('it', 15), ('for', 16), ('on', 17), ('s', 18), ('as', 19)] \n",
      "\n",
      "Mapping identifiant -> vocabulaire ['</s>', '.', ',', 'the', 'of', \"'\", 'in', '-', 'and', ')', '(', 'a', 'to', 'is', 'was', 'it', 'for', 'on', 's', 'as'] \n",
      "\n",
      "Vecteur de représentation des mots  the et bird tensor([[ 1.0399e-02, -1.8291e-01,  7.6084e-02, -1.8541e-01,  9.9364e-02,\n",
      "          1.9839e-01, -1.6722e-01, -1.3452e-02, -2.8677e-04,  2.6706e-03,\n",
      "          9.7921e-02, -1.1183e-01, -1.3611e-01,  1.3828e-01,  1.3663e-03,\n",
      "          8.9178e-02,  6.2126e-02,  1.3424e-01,  1.9727e-02, -1.3894e-01],\n",
      "        [ 7.1273e-01,  9.0417e-02,  2.3113e-01, -2.4010e-01,  3.4579e-01,\n",
      "         -2.9609e-01,  1.3830e-01, -3.0154e-01, -1.8437e-01, -1.2250e-01,\n",
      "         -4.9281e-01, -1.3723e-01, -4.2864e-03, -1.0009e-01, -4.8112e-01,\n",
      "          2.6919e-01, -2.1156e-01, -1.5168e-03, -1.5283e-01,  2.9936e-01]])\n",
      "Vecteur du mot bird :  tensor([ 0.7127,  0.0904,  0.2311, -0.2401,  0.3458, -0.2961,  0.1383, -0.3015,\n",
      "        -0.1844, -0.1225, -0.4928, -0.1372, -0.0043, -0.1001, -0.4811,  0.2692,\n",
      "        -0.2116, -0.0015, -0.1528,  0.2994])\n"
     ]
    }
   ],
   "source": [
    "print(\"Mapping vocabulaire -> identifiant\",list(fasttext.stoi.items())[:20],\"\\n\")\n",
    "print(\"Mapping identifiant -> vocabulaire\",fasttext.itos[:20],\"\\n\")\n",
    "print(\"Vecteur de représentation des mots  the et bird\", fasttext.get_vecs_by_tokens([\"the\",\"birds\"])[:,:20])\n",
    "print(\"Vecteur du mot bird : \", fasttext.vectors[fasttext.stoi[\"birds\"]][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-product",
   "metadata": {},
   "source": [
    "## <span class=\"alert-success\"> Exercice : manipulation des représentations </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-bargain",
   "metadata": {},
   "source": [
    "**TensorBoard** possède un très bon visualiseur d'embeddings qui permet de choisir entre TSNE et ACP pour la méthode de réduction de dimensions. On peut bien sûr utiliser tout autre outil de visualisation.\n",
    "Visualisez les embeddings. Notez la répartition des mots dans l'espace. \n",
    "Pour mieux appréhender la distance entre les mots, visualisez les similarités entre mots en traçant la heatmap des produits scalaires entre chaque couple de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "gentle-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f\"{TB_PATH}/embexemples\"+time.asctime())\n",
    "\n",
    "writer.add_embedding(vectors,metadata=vocab.get_itos())\n",
    "\n",
    "## Visualisation de la matrice de similarité mat, avec la liste des labels correspondant\n",
    "def viz_sim(mat,labels):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.imshow(mat)\n",
    "    ax.set_xticks(range(len(labels)))\n",
    "    ax.set_yticks(range(len(labels)))\n",
    "    _=ax.set_xticklabels(labels,rotation=90),ax.set_yticklabels(labels)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualisation de la matrice de similarité (produit scalaire entre les représentations des mots)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-discipline",
   "metadata": {},
   "source": [
    "Une première représentation d'une phrase peut être réalisée en concatenant les représentations de tous ses tokens sur un même vecteur. Visualisez la heatmap des similarités entre phrases avec cette représentation. Quelle est le problème évident de ce genre de représentation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concaténation des tokens des phrases et visualisation de la similarité\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-surfing",
   "metadata": {},
   "source": [
    "Une autre représentation consiste à faire la moyenne des représentations des tokens de la phrase. Visualisez la similarité en utilisant cette représentation. Améliore-t-elle les résultats ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construction de l'embedding moyen d'une phrase et visualisation des similarités\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "902a52bcf4503a473db011f1937bdfe17613b08622219712e0110e48c4958c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
